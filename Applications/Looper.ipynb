{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import librosa\n",
    "import madmom\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorly\n",
    "import tensorly.decomposition as tld\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm(audio_file, n_templates=[0,0,0], output_savename=\"extracted_loop\"):\n",
    "    \"\"\"Complete pipeline of algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    audio_file : string\n",
    "        Path to audio file to be loaded and analysed.\n",
    "    n_templates : list of length 3\n",
    "        The number of sound, rhythm and loop templates.\n",
    "        Default value (0,0,0) causes the script to estimate reasonable values.\n",
    "    output_savename: : string\n",
    "        Base string for saved output filenames.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A set of files containing the extracted loops.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> run_algorithm(\"example_song.mp3\", [40,20,7], \"extracted_loop\")\n",
    "    \n",
    "    See also\n",
    "    --------\n",
    "    tensorly.decomposition.non_negative_tucker\n",
    "    \"\"\"\n",
    "    assert os.path.exists(audio_file)\n",
    "    assert len(n_templates)==3\n",
    "    assert type(n_templates) is list\n",
    "    # Load mono audio:\n",
    "    signal_mono, fs = librosa.load(audio_file, sr=None, mono=True)\n",
    "    # Use madmom to estimate the downbeat times:\n",
    "    downbeat_times = get_downbeats(signal_mono)\n",
    "    # Convert times to frames so we segment signal:\n",
    "    downbeat_frames = librosa.time_to_samples(downbeat_times, sr=fs)\n",
    "    # Create spectral cube out of signal:\n",
    "    spectral_cube = make_spectral_cube(signal_mono, downbeat_frames)\n",
    "    # Validate the input n_templates (inventing new ones if any is wrong):\n",
    "    n_sounds, n_rhythms, n_loops = validate_template_sizes(spectral_cube, n_templates)\n",
    "    # Use TensorLy to do the non-negative Tucker decomposition:\n",
    "    core, factors = tld.non_negative_tucker(np.abs(spectral_cube), [n_sounds, n_rhythms, n_loops], n_iter_max=500, verbose=True)\n",
    "    # Reconstruct each loop:\n",
    "    for ith_loop in range(n_loops):\n",
    "        # Multiply templates together to get real loop spectrum:\n",
    "        loop_spectrum = create_loop_spectrum(factors[0], factors[1], core[:,:,ith_loop])\n",
    "        # Choose best bar to reconstruct from (we will use its phase):\n",
    "        bar_ind = choose_bar_to_reconstruct(factors[2], ith_loop)\n",
    "        # Reconstruct loop signal by masking original spectrum:\n",
    "        ith_loop_signal = get_loop_signal(loop_spectrum, spectral_cube[:,:,bar_ind])\n",
    "        # Write signal to disk:\n",
    "        librosa.output.write_wav(\"{0}_{1}.wav\".format(output_savename,ith_loop), ith_loop_signal, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_downbeats(signal):\n",
    "    \"\"\"Use madmom package to estimate downbeats for an audio signal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : np.ndarray [shape=(n,), dtype=float]\n",
    "        Input mono audio signal.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    downbeat_times : np.ndarray [shape=(n,), dtype=float]\n",
    "        List of estimated downbeat times in seconds.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> signal_mono, fs = librosa.load(\"example_song.mp3\", sr=None, mono=True)\n",
    "    >>> get_downbeats(signal_mono)\n",
    "    array([1.000e-02, 1.890e+00, 3.760e+00, 5.630e+00, 7.510e+00, 9.380e+00,\n",
    "           1.126e+01, 1.313e+01, 1.501e+01, 1.688e+01, 1.876e+01, 2.064e+01,\n",
    "           2.251e+01, 2.439e+01, 2.626e+01, 2.814e+01, 3.002e+01, 3.189e+01,\n",
    "           3.376e+01, 3.564e+01, 3.751e+01, 3.939e+01, 4.126e+01, 4.314e+01,\n",
    "           4.501e+01, 4.689e+01, 4.876e+01, 5.063e+01, 5.251e+01, 5.439e+01,\n",
    "           5.626e+01, 5.813e+01])\n",
    "    \n",
    "    See Also\n",
    "    --------\n",
    "    madmom.features.downbeats.RNNDownBeatProcessor\n",
    "    madmom.features.downbeats.DBNDownBeatTrackingProcessor\n",
    "    \"\"\"\n",
    "    act = madmom.features.downbeats.RNNDownBeatProcessor()(signal)\n",
    "    proc = madmom.features.downbeats.DBNDownBeatTrackingProcessor(beats_per_bar=[3, 4], fps=100)\n",
    "    processor_output = proc(act)\n",
    "    downbeat_times = processor_output[processor_output[:,1]==1,0]\n",
    "    return downbeat_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spectral_cube(signal_mono, downbeat_frames):\n",
    "    \"\"\"Convert audio signal into a spectral cube using\n",
    "    specified downbeat frames.\n",
    "\n",
    "    An STFT is taken of each segment of audio, and\n",
    "    these STFTs are stacked into a 3rd dimension.\n",
    "    \n",
    "    The STFTs may have different lengths; they are\n",
    "    zero-padded to the length of the longest STFT.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal_mono : np.ndarray [shape=(n,), dtype=float]\n",
    "        one-dimensional audio signal to convert\n",
    "    downbeat_frames : np.ndarray [shape=(n,), dtype=int]\n",
    "        list of frames separating downbeats (or whatever\n",
    "        time interval is desired)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tensor  : np.ndarray [shape=(n1,n2,n3), dtype=complex64]\n",
    "        tensor containing spectrum slices\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> signal_mono, fs = librosa.load(\"example_song.mp3\", sr=None, mono=True)\n",
    "    >>> downbeat_times = get_downbeats(signal_mono)\n",
    "    >>> downbeat_frames = librosa.time_to_samples(downbeat_times, sr=fs)\n",
    "    >>> spectral_cube = make_spectral_cube(signal_mono, downbeat_frames)\n",
    "    >>> spectral_cube.shape\n",
    "    (1025, 162, 31)\n",
    "    >>> spectral_cube[:2,:2,:2]\n",
    "    array([[[ 18.08905602+0.00000000e+00j, -20.48682976+0.00000000e+00j],\n",
    "            [-16.07670403+0.00000000e+00j, -44.98669434+0.00000000e+00j]],\n",
    "\n",
    "           [[-19.45080566+3.66026653e-15j,  -8.5700922 +3.14418630e-16j],\n",
    "            [  1.01680577-3.67251587e+01j,  35.03190231-2.13507919e+01j]]])\n",
    "    \"\"\"\n",
    "    assert len(signal_mono.shape) == 1\n",
    "    # For each span of audio, compute the FFT using librosa defaults.\n",
    "    fft_per_span = [librosa.core.stft(signal_mono[b1:b2]) for b1,b2 in zip(downbeat_frames[:-1],downbeat_frames[1:])]\n",
    "    # Tensor size 1: the number of frequency bins\n",
    "    freq_bins = fft_per_span[0].shape[0]\n",
    "    # Tensor size 2: the length of the STFTs.\n",
    "    # This could vary for each span; use the maximum.\n",
    "    rhyt_bins = np.max([fpb.shape[1] for fpb in fft_per_span])\n",
    "    # Tensor size 3: the number of spans.\n",
    "    bar_bins = len(fft_per_span)\n",
    "    tensor = np.zeros((freq_bins, rhyt_bins, bar_bins)).astype(complex)\n",
    "    for i in range(bar_bins):\n",
    "        tensor[:,:fft_per_span[i].shape[1],i] = fft_per_span[i]\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_template_sizes(spectral_cube, n_templates):\n",
    "    \"\"\"Ensure that specified number of estimated templates are valid.\n",
    "    Values must be greater than 1 and strictly less than\n",
    "    the corresponding dimension of the original tensor.\n",
    "    So, if the tensor has size [1025,100,20], then\n",
    "    n_templates = [99,99,10] is valid (though unadvised), while\n",
    "    n_templates = [30,20,20] is invalid.\n",
    "    \n",
    "    If ANY of the values for n_templates are invalid, than\n",
    "    get_recommended_template_sizes() is used to obtain\n",
    "    replacement values for n_templates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectral_cube : np.ndarray [shape=(n1,n2,n3)]\n",
    "        Original tensor to be modeled.\n",
    "    n_templates : list [shape=(3,), dtype=int]\n",
    "        Proposed numbers of templates.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output_n_templates : np.ndarray [shape=(3,), dtype=int]\n",
    "        Validated numbers of templates.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> validate_template_sizes(np.zeros((1025, 162, 31)), [100, 50, 20])\n",
    "    array([100, 50, 20])\n",
    "    >>> validate_template_sizes(np.zeros((1025, 162, 31)), [0, 0, 0])\n",
    "    array([63, 21,  7])\n",
    "    >>> validate_template_sizes(np.zeros((1025, 162, 31)), [100, 50, 40])\n",
    "    array([63, 21, 7])\n",
    "    \n",
    "    See Also\n",
    "    --------\n",
    "    get_recommended_template_sizes\n",
    "    \"\"\"\n",
    "    max_template_sizes = np.array(spectral_cube.shape) - 1\n",
    "    min_template_sizes = np.ones_like(max_template_sizes)\n",
    "    big_enough = np.all(min_template_sizes <= n_templates)\n",
    "    small_enough = np.all(n_templates <= max_template_sizes)\n",
    "    valid = big_enough & small_enough\n",
    "    if valid:\n",
    "        return n_templates\n",
    "    else:\n",
    "        return get_recommended_template_sizes(spectral_cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purify_core_tensor(core, factors, new_rank, dim_to_reduce=2):\n",
    "    \"\"\"Reduce the size of the core tensor by modelling repeated content\n",
    "    across loop recipes. The output is a more \"pure\" set of loop\n",
    "    recipes that should be more distinct from each other.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    core : np.ndarray [shape=(n1,n2,n3)]\n",
    "        Core tensor to be compressed.\n",
    "    factors : list [shape=(3,), dtype=np.ndarray]\n",
    "        List of estimated templates\n",
    "    new_rank : int\n",
    "        The new size for the core tensor\n",
    "    dim_to_reduce : int\n",
    "        The dimension along which to compress the core tensor.\n",
    "        (Default value 2 will reduce the number of loop types.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_core : np.ndarray [shape=(n1,n2,new_rank)]\n",
    "        Compressed version of the core tensor\n",
    "    new_factors : list [shape=(3,), dtype=np.ndarray]\n",
    "        New list of templates.\n",
    "        Note: two templates will be the same as before;\n",
    "            only the template for the compressed dimension\n",
    "            will be different.    \n",
    "    \"\"\"\n",
    "    assert new_rank < core.shape[dim_to_reduce]\n",
    "    X = tensorly.unfold(core,dim_to_reduce)\n",
    "    model = NMF(n_components=new_rank, init='nndsvd', random_state=0)\n",
    "    W = model.fit_transform(X)\n",
    "    H = model.components_\n",
    "    # Re-construct core tensor and factors based on NMF factors from core tensor:\n",
    "    new_shape = list(core.shape)\n",
    "    new_shape[dim_to_reduce] = new_rank\n",
    "    new_core = tensorly.fold(H, dim_to_reduce, new_shape)\n",
    "    new_factors = copy.copy(factors)\n",
    "    new_factors[dim_to_reduce] = np.dot(factors[dim_to_reduce],W)\n",
    "    return new_core, new_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommended_template_sizes(spectral_cube):\n",
    "    \"\"\"Propose reasonable values for numbers of templates\n",
    "    to estimate.\n",
    "    \n",
    "    If a dimension of the tensor is N, then N^(6/10), rounded\n",
    "    down, seems to give a reasonable value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectral_cube : np.ndarray [shape=(n1,n2,n3)]\n",
    "        Original tensor to be modeled.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    recommended_sizes : np.ndarray [shape=(len(spectral_cube.shape),), dtype=float]\n",
    "        Suggested number of templates.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> get_recommended_template_sizes(np.zeros((100,200,300)))\n",
    "    array([15, 23, 30])\n",
    "    >>> get_recommended_template_sizes(np.zeros((4,400,40000)))\n",
    "    array([  1,  36, 577])\n",
    "    \"\"\"\n",
    "    max_template_sizes = np.array(spectral_cube.shape) - 1\n",
    "    min_template_sizes = np.ones_like(max_template_sizes)\n",
    "    recommended_sizes = np.floor(max_template_sizes**.6).astype(int)\n",
    "    recommended_sizes = np.max((recommended_sizes, min_template_sizes),axis=0)\n",
    "    assert np.all(min_template_sizes <= recommended_sizes)\n",
    "    assert np.all(recommended_sizes <= max_template_sizes)\n",
    "    return recommended_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loop_spectrum(sounds, rhythms, core_slice):\n",
    "    \"\"\"Recreate loop spectrum from a slice of the core tensor\n",
    "    and the first two templates, the sounds and rhythms.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sounds : np.ndarray [shape=(n_frequency_bins, n_sounds), dtype=float]\n",
    "        The sound templates, one spectral template per column.\n",
    "    rhythms : np.ndarray [shape=(n_time_bins, n_rhythms), dtype=float]\n",
    "        The rhythm templates, or time-in-bar activations functions.\n",
    "        One rhythm template per column.\n",
    "    core_slice : np.ndarray [shape=(n_sounds, n_rhythms)]\n",
    "        A slice of the core tensor giving the recipe for one loop.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loop_spectrum : np.ndarray [shape=(n_frequency_bins, n_time_bins), dtype=float]\n",
    "        Reconstruction of spectrum.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.random.seed(0)\n",
    "    >>> factors = [np.abs(np.random.randn(1025, 63)),\n",
    "            np.abs(np.random.randn(162, 21)),\n",
    "            np.abs(np.random.randn(31, 7))]\n",
    "    >>> core = np.abs(np.random.randn(63,21,7))\n",
    "    >>> create_loop_spectrum(factors[0], factors[1], core[:,:,0])\n",
    "    array([[727.4153606 , 728.64591236, 625.76726056, ..., 512.94167141,\n",
    "            592.2098947 , 607.10457107],\n",
    "           [782.11991843, 778.09690543, 682.71895323, ..., 550.43525375,\n",
    "            636.51448493, 666.35600624],\n",
    "           [733.96209316, 720.17586837, 621.80762807, ..., 501.51192504,\n",
    "            590.14018676, 605.44147057],\n",
    "           ...,\n",
    "           [772.43712078, 758.88473642, 654.35159419, ..., 522.69754588,\n",
    "            628.84580165, 641.66347072],\n",
    "           [677.58720601, 666.52484723, 583.92269705, ..., 471.24362278,\n",
    "            558.17441475, 573.31864635],\n",
    "           [768.96634561, 758.85553214, 639.21515256, ..., 525.83186141,\n",
    "            634.04799161, 644.35772338]])\n",
    "    \"\"\"\n",
    "    loop_spectrum = np.dot(np.dot(sounds, core_slice), rhythms.transpose())\n",
    "    return loop_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_bar_to_reconstruct(loop_templates, ith_loop):\n",
    "    \"\"\"...Choose... bar... to... reconstruct!\n",
    "    \n",
    "    For now, it just choose the bar with the largest activation.\n",
    "    More information could / should be included, like reducing\n",
    "    cross-talk, which would mean considering the activations (but\n",
    "    ideally the relative *loudnesses*) of the other loops.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    loop_templates : np.ndarray [shape=(n_bars, n_loop_types), dtype=float]\n",
    "        The loop activation templates, one template per column.\n",
    "    ith_loop : int\n",
    "        The index of the loop template.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bar_ind : int\n",
    "        The index of the bar to choose.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.random.seed(0)\n",
    "    >>> factors = [np.abs(np.random.randn(1025, 63)),\n",
    "            np.abs(np.random.randn(162, 21)),\n",
    "            np.abs(np.random.randn(31, 7))]\n",
    "    >>> choose_bar_to_reconstruct(factors[2], 0)\n",
    "    10\n",
    "    \"\"\"\n",
    "    bar_ind = np.argmax(loop_templates[:,ith_loop])\n",
    "    return bar_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loop_signal(loop_spectrum, original_spectrum):\n",
    "    \"\"\"Reconstruct the signal for a loop given its spectrum\n",
    "    and the original spectrum.\n",
    "    \n",
    "    The original spectrum is used as the basis, and the reconstructed\n",
    "    loop spectrum is used to mask the spectrum.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    loop_spectrum : np.ndarray [shape=(n_freq_bins, n_time_bins_1), dtype=float]\n",
    "        Reconstructed loop spectrum (real)\n",
    "    original_spectrum : np.ndarray [shape=(n_freq_bins, n_time_bins_2), dtype=complex]\n",
    "        Original spectrum (complex; possibly different length of time)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    signal : np.ndarray [shape=(n,), dtype=float]\n",
    "        Estimated signal of isolated loop.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> np.random.seed(0)\n",
    "    >>> random_matrix = np.random.randn(1025,130)\n",
    "    >>> loop_spectrum = np.abs(random_matrix) / np.max(random_matrix)\n",
    "    >>> random_matrix_2 = np.random.randn(1025,130)\n",
    "    >>> loop_spectrum_2 = np.abs(random_matrix_2) / np.max(random_matrix_2)\n",
    "    >>> get_loop_signal(loop_spectrum, loop_spectrum_2)\n",
    "    array([-5.7243928e-04, -2.3625907e-04, -3.8087784e-04, ...,\n",
    "            9.2569360e-05,  3.9195133e-04, -2.4777438e-04], dtype=float32)\n",
    "        \n",
    "    See also\n",
    "    --------\n",
    "    librosa.util.softmask\n",
    "    \"\"\"\n",
    "    assert loop_spectrum.shape[0] == original_spectrum.shape[0]\n",
    "    min_length = np.min((loop_spectrum.shape[1], original_spectrum.shape[1]))\n",
    "    orig_mag, orig_phase = librosa.magphase(original_spectrum)\n",
    "    mask = librosa.util.softmask(loop_spectrum[:,:min_length], orig_mag[:,:min_length], power=1)\n",
    "    masked_spectrum = original_spectrum[:,:min_length] * mask\n",
    "    signal = librosa.core.istft(masked_spectrum)\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error=0.6179850611230522, variation=0.005703809007929328.\n",
      "reconstruction error=0.610230558500448, variation=0.007754502622604131.\n",
      "reconstruction error=0.6000840642037207, variation=0.010146494296727315.\n",
      "reconstruction error=0.587761143866124, variation=0.012322920337596743.\n",
      "reconstruction error=0.5741594468162394, variation=0.013601697049884565.\n",
      "reconstruction error=0.5603048675313641, variation=0.013854579284875324.\n",
      "reconstruction error=0.5464938662356071, variation=0.013811001295756964.\n",
      "reconstruction error=0.5324755203830667, variation=0.01401834585254047.\n",
      "reconstruction error=0.5188389772704957, variation=0.013636543112571009.\n",
      "reconstruction error=0.5069801633450972, variation=0.011858813925398448.\n",
      "reconstruction error=0.49766928384637515, variation=0.009310879498722058.\n",
      "reconstruction error=0.4907136122031824, variation=0.006955671643192773.\n",
      "reconstruction error=0.48546888638326435, variation=0.005244725819918028.\n",
      "reconstruction error=0.4813199449925478, variation=0.004148941390716532.\n",
      "reconstruction error=0.47783351371359994, variation=0.003486431278947877.\n",
      "reconstruction error=0.474728808612607, variation=0.0031047051009929216.\n",
      "reconstruction error=0.4718154769492512, variation=0.0029133316633558337.\n",
      "reconstruction error=0.4689499543722326, variation=0.002865522577018609.\n",
      "reconstruction error=0.46601672081110324, variation=0.0029332335611293447.\n",
      "reconstruction error=0.46293719372037984, variation=0.0030795270907233996.\n",
      "reconstruction error=0.45971507353591834, variation=0.0032221201844614966.\n",
      "reconstruction error=0.45648662565752623, variation=0.0032284478783921045.\n",
      "reconstruction error=0.4534396857756813, variation=0.0030469398818449567.\n",
      "reconstruction error=0.45064287410204534, variation=0.002796811673635935.\n",
      "reconstruction error=0.44804949294122043, variation=0.0025933811608249147.\n",
      "reconstruction error=0.4455944395056257, variation=0.002455053435594712.\n",
      "reconstruction error=0.44323435283212187, variation=0.0023600866735038473.\n",
      "reconstruction error=0.4409462124332841, variation=0.00228814039883779.\n",
      "reconstruction error=0.43871855279162375, variation=0.002227659641660329.\n",
      "reconstruction error=0.4365452326271597, variation=0.002173320164464032.\n",
      "reconstruction error=0.43442210085536037, variation=0.002123131771799347.\n",
      "reconstruction error=0.4323457156982345, variation=0.002076385157125882.\n",
      "reconstruction error=0.4303133100568467, variation=0.002032405641387791.\n",
      "reconstruction error=0.42832308779166695, variation=0.001990222265179753.\n",
      "reconstruction error=0.42637414629690595, variation=0.0019489414947609918.\n",
      "reconstruction error=0.42446596874860115, variation=0.0019081775483048014.\n",
      "reconstruction error=0.42259795248789067, variation=0.001868016260710481.\n",
      "reconstruction error=0.4207693568079321, variation=0.0018285956799585779.\n",
      "reconstruction error=0.4189795880704062, variation=0.0017897687375258986.\n",
      "reconstruction error=0.41722845300915695, variation=0.0017511350612492427.\n",
      "reconstruction error=0.41551611555877044, variation=0.001712337450386514.\n",
      "reconstruction error=0.4138427781002293, variation=0.0016733374585411465.\n",
      "reconstruction error=0.412208301425285, variation=0.0016344766749443185.\n",
      "reconstruction error=0.41061198205455596, variation=0.0015963193707290158.\n",
      "reconstruction error=0.4090525856884622, variation=0.001559396366093757.\n",
      "reconstruction error=0.40752860373063243, variation=0.0015239819578297675.\n",
      "reconstruction error=0.40603862537894425, variation=0.0014899783516881815.\n",
      "reconstruction error=0.40458170543509164, variation=0.0014569199438526081.\n",
      "reconstruction error=0.40315763154963746, variation=0.0014240738854541801.\n",
      "reconstruction error=0.40176703553363724, variation=0.0013905960160002229.\n",
      "reconstruction error=0.4004113450979258, variation=0.0013556904357114319.\n",
      "reconstruction error=0.39909262082721836, variation=0.0013187242707074498.\n",
      "reconstruction error=0.3978133420665998, variation=0.001279278760618563.\n",
      "reconstruction error=0.39657618234073183, variation=0.0012371597258679645.\n",
      "reconstruction error=0.3953837748911438, variation=0.00119240744958804.\n",
      "reconstruction error=0.3942384546126387, variation=0.001145320278505113.\n",
      "reconstruction error=0.39314198898266056, variation=0.0010964656299781161.\n",
      "reconstruction error=0.392095348927733, variation=0.00104664005492755.\n",
      "reconstruction error=0.391098580766012, variation=0.0009967681617210067.\n",
      "reconstruction error=0.3901508105764416, variation=0.0009477701895704294.\n",
      "reconstruction error=0.3892503655081835, variation=0.0009004450682580933.\n",
      "reconstruction error=0.38839496399378787, variation=0.0008554015143956151.\n",
      "reconstruction error=0.3875819219727657, variation=0.00081304202102217.\n",
      "reconstruction error=0.3868083374669193, variation=0.0007735845058464141.\n",
      "reconstruction error=0.3860712362541897, variation=0.000737101212729574.\n",
      "reconstruction error=0.3853676768640531, variation=0.00070355939013661.\n",
      "reconstruction error=0.38469482105931296, variation=0.0006728558047401356.\n",
      "reconstruction error=0.38404997815893144, variation=0.0006448429003815259.\n",
      "reconstruction error=0.3834306307337318, variation=0.0006193474251996456.\n",
      "reconstruction error=0.38283444740739897, variation=0.000596183326332822.\n",
      "reconstruction error=0.38225928678335014, variation=0.0005751606240488316.\n",
      "reconstruction error=0.3817031952603265, variation=0.0005560915230236607.\n",
      "reconstruction error=0.38116440069542, variation=0.000538794564906464.\n",
      "reconstruction error=0.38064130338483443, variation=0.0005230973105855852.\n",
      "reconstruction error=0.3801324655118625, variation=0.0005088378729719012.\n",
      "reconstruction error=0.3796365999511442, variation=0.0004958655607183449.\n",
      "reconstruction error=0.37915255906194023, variation=0.0004840408892039516.\n",
      "reconstruction error=0.37867932383590897, variation=0.00047323522603126555.\n",
      "reconstruction error=0.37821599349933493, variation=0.00046333033657403044.\n",
      "reconstruction error=0.37776177543486905, variation=0.0004542180644658833.\n",
      "reconstruction error=0.37731597511905696, variation=0.0004458003158120949.\n",
      "reconstruction error=0.37687798570236003, variation=0.0004379894166969267.\n",
      "reconstruction error=0.37644727690983487, variation=0.0004307087925251585.\n",
      "reconstruction error=0.3760233831144985, variation=0.00042389379533636085.\n",
      "reconstruction error=0.3756058907071792, variation=0.0004174924073193087.\n",
      "reconstruction error=0.37519442520581403, variation=0.00041146550136517135.\n",
      "reconstruction error=0.3747886388466011, variation=0.00040578635921295625.\n",
      "reconstruction error=0.37438819961227965, variation=0.0004004392343214258.\n",
      "reconstruction error=0.3739927827342659, variation=0.0003954168780137546.\n",
      "reconstruction error=0.37360206564468185, variation=0.00039071708958404727.\n",
      "reconstruction error=0.3732157271730325, variation=0.0003863384716493723.\n",
      "reconstruction error=0.37283345150629316, variation=0.0003822756667393179.\n",
      "reconstruction error=0.37245493705288263, variation=0.0003785144534105278.\n",
      "reconstruction error=0.3720799097964006, variation=0.00037502725648203006.\n",
      "reconstruction error=0.37170813986889717, variation=0.0003717699275034292.\n",
      "reconstruction error=0.37133945884062797, variation=0.0003686810282692021.\n",
      "reconstruction error=0.3709737737896214, variation=0.0003656850510065923.\n",
      "reconstruction error=0.370611073217643, variation=0.00036270057197840266.\n",
      "reconstruction error=0.3702514203814707, variation=0.00035965283617228616.\n",
      "reconstruction error=0.36989493250337113, variation=0.00035648787809955396.\n",
      "reconstruction error=0.36954174927210787, variation=0.00035318323126326545.\n",
      "reconstruction error=0.3691919988492993, variation=0.00034975042280854796.\n",
      "reconstruction error=0.36884577121523254, variation=0.0003462276340667758.\n",
      "reconstruction error=0.36850310567156974, variation=0.0003426655436628012.\n",
      "reconstruction error=0.3681639933586232, variation=0.0003391123129465323.\n",
      "reconstruction error=0.36782839032138276, variation=0.0003356030372404506.\n",
      "reconstruction error=0.36749623452955205, variation=0.00033215579183071275.\n",
      "reconstruction error=0.3671674613050248, variation=0.00032877322452723456.\n",
      "reconstruction error=0.3668420141190672, variation=0.0003254471859576169.\n",
      "reconstruction error=0.3665198500318732, variation=0.0003221640871939879.\n",
      "reconstruction error=0.36620094045654455, variation=0.00031890957532865194.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error=0.36588526852545283, variation=0.0003156719310917211.\n",
      "reconstruction error=0.3655728244605631, variation=0.00031244406488972754.\n",
      "reconstruction error=0.3652636002515636, variation=0.0003092242089994812.\n",
      "reconstruction error=0.3649575847231432, variation=0.00030601552842041135.\n",
      "reconstruction error=0.3646547597496466, variation=0.000302824973496596.\n",
      "reconstruction error=0.36435509798825305, variation=0.00029966176139356593.\n",
      "reconstruction error=0.3640585621264168, variation=0.0002965358618362557.\n",
      "reconstruction error=0.36376510535944073, variation=0.0002934567669760635.\n",
      "reconstruction error=0.36347467267906763, variation=0.00029043268037309833.\n",
      "reconstruction error=0.3631872025571468, variation=0.00028747012192081867.\n",
      "reconstruction error=0.36290262870150275, variation=0.0002845738556440658.\n",
      "reconstruction error=0.362620881684184, variation=0.0002817470173187564.\n",
      "reconstruction error=0.3623418903509574, variation=0.0002789913332266192.\n",
      "reconstruction error=0.362065582994759, variation=0.00027630735619837976.\n",
      "reconstruction error=0.36179188831451675, variation=0.0002736946802422424.\n",
      "reconstruction error=0.36152073619395325, variation=0.00027115212056350035.\n",
      "reconstruction error=0.36125205833413404, variation=0.0002686778598192108.\n",
      "reconstruction error=0.3609857887675258, variation=0.00026626956660824597.\n",
      "reconstruction error=0.3607218642754752, variation=0.00026392449205059343.\n",
      "reconstruction error=0.3604602247272493, variation=0.0002616395482258893.\n",
      "reconstruction error=0.36020081335770604, variation=0.00025941136954327204.\n",
      "reconstruction error=0.35994357700099955, variation=0.0002572363567064917.\n",
      "reconstruction error=0.35968846629880746, variation=0.0002551107021920851.\n",
      "reconstruction error=0.35943543590187504, variation=0.0002530303969324188.\n",
      "reconstruction error=0.3591844446823219, variation=0.00025099121955313164.\n",
      "reconstruction error=0.3589354559701296, variation=0.00024898871219231067.\n",
      "reconstruction error=0.3586884378197925, variation=0.0002470181503371194.\n",
      "reconstruction error=0.35844336330174137, variation=0.0002450745180511138.\n",
      "reconstruction error=0.3582002107979297, variation=0.0002431525038116833.\n",
      "reconstruction error=0.3579589642630436, variation=0.00024124653488610814.\n",
      "reconstruction error=0.3577196133948141, variation=0.00023935086822945983.\n",
      "reconstruction error=0.3574821536433724, variation=0.0002374597514417376.\n",
      "reconstruction error=0.35724658598643294, variation=0.00023556765693943937.\n",
      "reconstruction error=0.35701291641000205, variation=0.00023366957643089492.\n",
      "reconstruction error=0.3567811550666454, variation=0.00023176134335667342.\n",
      "reconstruction error=0.3565513151326361, variation=0.00022983993400926828.\n",
      "reconstruction error=0.356323411442051, variation=0.0002279036905851184.\n",
      "reconstruction error=0.35609745902500156, variation=0.00022595241704942426.\n",
      "reconstruction error=0.35587347170253797, variation=0.00022398732246359243.\n",
      "reconstruction error=0.3556514608826641, variation=0.0002220108198738857.\n",
      "reconstruction error=0.3554314346617667, variation=0.00022002622089739576.\n",
      "reconstruction error=0.355213397276457, variation=0.0002180373853096773.\n",
      "reconstruction error=0.35499734889084156, variation=0.0002160483856154527.\n",
      "reconstruction error=0.35478328566010664, variation=0.00021406323073491773.\n",
      "reconstruction error=0.3545711999907408, variation=0.00021208566936581352.\n",
      "reconstruction error=0.35436108091943164, variation=0.0002101190713091894.\n",
      "reconstruction error=0.354152914548346, variation=0.0002081663710856163.\n",
      "reconstruction error=0.35394668449500705, variation=0.00020623005333897382.\n",
      "reconstruction error=0.35374237233282674, variation=0.000204312162180309.\n",
      "reconstruction error=0.35353995801034527, variation=0.00020241432248147007.\n",
      "reconstruction error=0.3533394202432161, variation=0.00020053776712919413.\n",
      "reconstruction error=0.35314073687444497, variation=0.00019868336877110204.\n",
      "reconstruction error=0.3529438851975952, variation=0.00019685167684979632.\n",
      "reconstruction error=0.35274884223606845, variation=0.00019504296152672573.\n",
      "reconstruction error=0.3525555849703382, variation=0.00019325726573027335.\n",
      "reconstruction error=0.3523640905044636, variation=0.00019149446587457541.\n",
      "reconstruction error=0.35217433616365246, variation=0.0001897543408111435.\n",
      "reconstruction error=0.35198629951594657, variation=0.00018803664770589146.\n",
      "reconstruction error=0.35179995831351213, variation=0.00018634120243443686.\n",
      "reconstruction error=0.3516152903522682, variation=0.00018466796124394502.\n",
      "reconstruction error=0.3514322732528621, variation=0.000183017099406102.\n",
      "reconstruction error=0.3512508841711452, variation=0.00018138908171688728.\n",
      "reconstruction error=0.3510710994520512, variation=0.0001797847190939672.\n",
      "reconstruction error=0.35089289424706843, variation=0.00017820520498279535.\n",
      "reconstruction error=0.35071624212178537, variation=0.00017665212528306107.\n",
      "reconstruction error=0.3505411146860684, variation=0.00017512743571695966.\n",
      "reconstruction error=0.3503674812849325, variation=0.00017363340113590864.\n",
      "reconstruction error=0.35019530879244654, variation=0.0001721724924859669.\n",
      "reconstruction error=0.3500245615535553, variation=0.00017074723889121124.\n",
      "reconstruction error=0.34985520151854876, variation=0.0001693600350065605.\n",
      "reconstruction error=0.34968718861082376, variation=0.00016801290772500144.\n",
      "reconstruction error=0.3495204813595651, variation=0.0001667072512586687.\n",
      "reconstruction error=0.34935503781368027, variation=0.00016544354588482468.\n",
      "reconstruction error=0.3491908167311419, variation=0.00016422108253838497.\n",
      "reconstruction error=0.3490277790087717, variation=0.0001630377223701962.\n",
      "reconstruction error=0.3488658892827941, variation=0.000161889725977582.\n",
      "reconstruction error=0.34870511759312256, variation=0.0001607716896715461.\n",
      "reconstruction error=0.3485454409698362, variation=0.00015967662328636445.\n",
      "reconstruction error=0.34838684477592996, variation=0.00015859619390623525.\n",
      "reconstruction error=0.3482293236347947, variation=0.00015752114113526394.\n",
      "reconstruction error=0.34807288179165263, variation=0.00015644184314206333.\n",
      "reconstruction error=0.34791753280944876, variation=0.0001553489822038734.\n",
      "reconstruction error=0.3477632985791324, variation=0.00015423423031635242.\n",
      "reconstruction error=0.34761020772160395, variation=0.00015309085752845952.\n",
      "reconstruction error=0.3474582935561934, variation=0.00015191416541054936.\n",
      "reconstruction error=0.34730759188730825, variation=0.0001507016688851448.\n",
      "reconstruction error=0.3471581388972427, variation=0.00014945299006557944.\n",
      "reconstruction error=0.3470099694181634, variation=0.00014816947907925204.\n",
      "reconstruction error=0.3468631157899913, variation=0.00014685362817212777.\n",
      "reconstruction error=0.3467176074056185, variation=0.00014550838437277225.\n",
      "reconstruction error=0.346573470920725, variation=0.00014413648489353115.\n",
      "reconstruction error=0.3464307309853454, variation=0.00014273993537960994.\n",
      "reconstruction error=0.3462894112593406, variation=0.00014131972600478493.\n",
      "reconstruction error=0.3461495354202593, variation=0.00013987583908131596.\n",
      "reconstruction error=0.3460111278703177, variation=0.00013840754994159932.\n",
      "reconstruction error=0.3458742139032611, variation=0.00013691396705656222.\n",
      "reconstruction error=0.34573881919694177, variation=0.00013539470631934725.\n",
      "reconstruction error=0.34560496863797935, variation=0.00013385055896242282.\n",
      "reconstruction error=0.34547268463293856, variation=0.00013228400504078364.\n",
      "reconstruction error=0.3453419851812559, variation=0.00013069945168264763.\n",
      "reconstruction error=0.34521288204522227, variation=0.0001291031360336481.\n",
      "reconstruction error=0.3450853793337513, variation=0.0001275027114709948.\n",
      "reconstruction error=0.3449594727246254, variation=0.00012590660912586982.\n",
      "reconstruction error=0.34483514941294874, variation=0.00012432331167666621.\n",
      "reconstruction error=0.3447123887325233, variation=0.00012276068042543775.\n",
      "reconstruction error=0.3445911632891068, variation=0.00012122544341647279.\n",
      "reconstruction error=0.3444714403910076, variation=0.00011972289809925041.\n",
      "reconstruction error=0.3443531835639819, variation=0.00011825682702565343.\n",
      "reconstruction error=0.34423635397871954, variation=0.00011682958526237908.\n",
      "reconstruction error=0.3441209116790999, variation=0.00011544229961962804.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error=0.3440068165589094, variation=0.00011409512019050494.\n",
      "reconstruction error=0.3438940290817652, variation=0.00011278747714421611.\n",
      "reconstruction error=0.34378251076956495, variation=0.00011151831220024278.\n",
      "reconstruction error=0.34367222449978446, variation=0.00011028626978049072.\n",
      "reconstruction error=0.3435631346556499, variation=0.0001090898441345467.\n",
      "reconstruction error=0.34345520716992384, variation=0.00010792748572607813.\n",
      "reconstruction error=0.3433484094964471, variation=0.00010679767347671065.\n",
      "reconstruction error=0.34324271053618405, variation=0.00010569896026307868.\n",
      "reconstruction error=0.34313808053769546, variation=0.00010462999848859234.\n",
      "reconstruction error=0.34303449098622096, variation=0.00010358955147449223.\n",
      "reconstruction error=0.342931914491034, variation=0.00010257649518696788.\n",
      "reconstruction error=0.34283032467741587, variation=0.00010158981361813035.\n",
      "reconstruction error=0.34272969608697995, variation=0.00010062859043591388.\n",
      "reconstruction error=0.3426300040883926, variation=9.96919985873368e-05.\n",
      "converged in 236 iterations.\n"
     ]
    }
   ],
   "source": [
    "run_algorithm(\"mix1.wav\", n_templates=[0,0,0], output_savename=\"extracted_loop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Channel at 0x20d0a430310>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pygame.mixer.init()\n",
    "sound = pygame.mixer.Sound(\"extracted_loop_1.wav\")\n",
    "sound2 = pygame.mixer.Sound(\"extracted_loop_12.wav\")\n",
    "sound3 = pygame.mixer.Sound(\"extracted_loop_15.wav\")\n",
    "sound.play(-1)\n",
    "sound2.play(-1)\n",
    "sound3.play(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# import pygame\n",
    "# import pygame\n",
    "# pygame.init()\n",
    "# pygame.display.set_mode(pygame.display.list_modes()[-1]) # smallest resolution available\n",
    "# pygame.mixer.init()\n",
    "# pygame.mixer.music.load(\"sample1.wav\")\n",
    "# pygame.mixer.music.play(5) # repeat 5 times\n",
    "# pygame.mixer.music.queue(\"sample2.wav\")   # queue test2.wav after test.wav plays 5 times\n",
    "# clock = pygame.time.Clock()\n",
    "# clock.tick(10)\n",
    "# while pygame.mixer.music.get_busy():\n",
    "#     pygame.event.poll()\n",
    "#     clock.tick(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
